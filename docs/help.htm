<h2 style="text-align: center; font-size:40px;"><strong>Zoetic</strong></h2>
<p><a href="#Introduction">Introduction</a></p>
<p><a href="#Instructions">How to use Zoetic</a></p>
<p><a href="#Subprojects">Sub-projects</a></p>
<p><a href="#FAQ">Further discussion</a></p>
<p><a href="#Privacy">Privacy Statement&nbsp;</a></p>
<p style="text-align: center;">&nbsp;</p>
<p style="text-align: center;  font-size:30px;"><strong><a id="Introduction"></a>Introduction</strong></p>
<p>How has your appearance changed over the years? What about your children&rsquo;s? Your parents&rsquo;? Your garden&rsquo;s? What about the last few, very noisy, months of the construction site at the bottom of the road; going from ground breaking to an upmarket apartment block? If you want to visualise such changes, grab the photos and let Zoetic show you.</p>
<p><strong>What is Zoetic?</strong></p>
<p>Given a series of images, Zoetic produces a video of the images&rsquo; subject changing over time. The series would typically be either:</p>
<ol>
<li>A scene that is fairly static. For example, a landscape where the images depict the changing seasons, or a building construction site that moves from initial &ldquo;ground breaking&rdquo; to the building&rsquo;s completion.</li>
<img src="2a.jpg" alt="bins A" width="30%">
<img src="2b.jpg" alt="bins B" width="30%">
<p></p>
<img src="3a.jpg" alt="garden A" width="30%">
<img src="3b.jpg" alt="garden B" width="30%">
<p></p>
<img src="4a.jpg" alt="flat A" width="30%">
<img src="4b.jpg" alt="flat B" width="30%">
<img src="4c.jpg" alt="flat C" width="30%">
<pre>

</pre>
<li>Scenes of a consistent, but time-changing, object against differing backgrounds. The object might typically be a person. Perhaps a series of photographs showing the person from birth to as they appear today.</li>
<img src="1a.jpg" alt="boy A" width="30%">
<img src="1b.jpg" alt="boy B" width="30%">
<img src="1c.jpg" alt="boy C" width="30%">
</ol>
<p><strong>Zoetic is not</strong></p>
<ul>
<li>An image &ldquo;morpher&rdquo; which produces unnatural results or requires a great deal of skill from the user.</li>
<li>An application that requires carefully controlled scenes with identical camera and lighting conditions from one shot to the next.</li>
</ul>
<pre>

</pre>
<p><strong>Examples and video instructions:&nbsp;</strong></p>
<p><a title="Examples and video instructions" href="https://www.youtube.com/channel/UC9DS_eg5oE_9HmVVYuUBkNw">https://www.youtube.com/channel/UC9DS_eg5oE_9HmVVYuUBkNw</a></p>
<pre>

</pre>
<p><strong>Functionality only available with the Professional version</strong></p>
<ul>
<li>No artificial constraint on image resolution and number of intermediate frames</li>
<li>Sub-projects can be used for scenes where it is difficult to identify the same alignment points in all a project's images</li>
<li>Video subtitles can be produced displaying the image dates</li>
<li>Any image of the series can be chosen to be the target image, not just the first</li>
<li>Enhanced image management</li>
<li>The average of the two registration points can be used as the alignment point.</li>
<li>Additional types of videos can be produced. Currently there are an additional two types:
<ul>
<li>Animate &ndash; a video showing the average image being produced from the individual images.</li>
<li>Throw &ndash; a video showing the images &lsquo;thrown&rsquo; in various ways. This video does not require marks to be set and hence can be generated immediately on adding images to a project.</li>
</ul>
</li>
</ul>
<pre>

</pre>
<p><strong>Feedback:&nbsp;</strong></p>
<p>Please send email to <a href="mailto:cyferltd@gmail.com?subject=Zoetic">cyferltd@gmail.com</a> rather than through the Play Store&rsquo;s review section.</p>

<p>&nbsp;</p>
<p style="text-align: center; font-size:30px;"><strong><a id="Instructions"></a>How to use Zoetic</strong></p>
<ol>
<li>Decide on the subject for the project and gather the required images. (This stage usually takes the most time unless you are very well organised!) Try to find images where the subject is not too small otherwise, after scaling/zooming, the resultant video may have an undesirably poor quality.</li>
<li>Load the images into Zoetic. The images can be loaded by sharing them from most photo apps, such as Google Photos or Android&rsquo;s Gallery. Select the required images. (Long pressing an image usually activates multiple selection.) Then activate the app&rsquo;s &ldquo;share&rdquo; function and choose Zoetic as the recipient.</li>
<li>When prompted by Zoetic, create a new project.</li>
<li>Use the Sort function to arrange the order of the images, delete any unwanted images and add/modify dates. In the Pro version, also set the target and select the images to be used.</li>
<li>Use the Mark Points function to select the registration points in all the images. Zoetic requires two user chosen registration points to align the images. These points must be of the same locations in all the images. Therefore they must be visible (or at least estimable) in all the images. For projects that use eyes for the locations, the eyes can be automatically detected. Either, from Zoetic&rsquo;s main menu choose the Detect Eyes function to process all the project&rsquo;s images, or from the Marker function choose the Eyes icon to detect eyes in the current image. In the former case, you will need to manually confirm that the eyes were correctly detected, especially for images containing more than one face.</li>
<li>Use the Crop function to specify the area of the image from which to create the video. If the series of images is of a scene photographed in a very consistent fashion (i.e. from exactly the same location and direction), a crop may not be necessary but this is very unlikely to be the case if the images were taken over an extended period. Using the &ldquo;averaged&rdquo; image of the series, select the required area (e.g. the area of the subject&rsquo;s head).</li>
<li>Create the video. This can take a while; how long will depend upon the resolution of the images, the required number of intermediate steps and the processing power of the device being used. During video creation, the device can be used for other functions since the creation will continue in the background.</li>
<li>Play the video. By default, the video is saved in the Movies folder and hence can be viewed from any app that handles viewing videos, including from within Zoetic.</li>
</ol>

<p>&nbsp;</p>
<p style="text-align: center; font-size:30px;"><a id="Subprojects"></a><strong>Sub-projects (Pro only)</strong></p>
Sometimes it is not possible to identify two points that are visible in all of a project’s images. Typically, this is when the view changes significantly. Such an example is the Flats project. The initial photo is of a garden, then there is a sequence of photos of ground clearing and, finally, a sequence of the building’s construction. In such a situation, the project may be split into one or more sub-projects. Each sub-project should be formed so that two points can be identified in all the images of the sub-project. The only constraint is that the last image of a sub-project must be the same image as the first image of the following sub-project. This continuity allows the sub-projects to be aligned to each other. </p> 
<p>
The Flat project consisted of three sub-projects using the points depicted here.
</p>
<img src="flat1.jpg" alt="flat1" width="100%">
<p>Points: window corners of flats to the left and flats to the right</p>
<img src="flat2.jpg" alt="flat2" width="100%">
<p>Points: two distinct points on the wooden fence</p>
<img src="flat3.jpg" alt="flat3" width="100%">
<p>Points: left and right wall corners on the first floor</p>

To produce a project with sub-projects:
<ol>
<li>In the Settings, enable “Process sub-projects”.</li>
<li>Create the sub-projects with names that are numerically consecutive e.g flat1, flat2, flat3…</li>
<li>Load the first project and ensure the target image has been set correctly. The target image settings of the other sub-projects are not used.</li>
<li>Make sure the last image of each sub-project is the same as the first image in the following sub-project, e.g. the last image in sub-project flat1 should be the same as the first image in sub-project flat2. A warning is displayed when this is not the case.</li>
<li>Now follow the usual process of creating the video (make any required changes to the Settings, set the crop, make the video). A message indicating the number of sub-projects being used will be shown.</li>
NB if in step 2’s example, flat2 was loaded instead of flat1, the flat1 project would be skipped and the video would be created using the target from flat2 and images from all the following sub-projects.</li>
</ol>



<p>&nbsp;</p>
<p style="text-align: center; font-size:30px;"><a id="FAQ"></a><strong>Further Discussion</strong></p>
<ul>
<li>The most important step in creating a good result is deciding on the two registration points. The first point is the actual alignment location and is the area that will be most &ldquo;in focus&rdquo; in the resulting video. The second point is used to calculate the scaling, translation and rotation factors, relative to the first point, required to align the images. This means the actual composition of the second point is not important (it could be the corner of an inconsequential doorpost) but it must be accurately locatable in all images.</li>
<li>The series is aligned to the first image (i.e. the target) in the series. (The Pro version allows any image to be selected as the target image.) Therefore, the first image should be a good example of the series and at the orientation and scale required of the video to be generated.</li>
<li>It is not necessary to mark all the images before a video is created though only the marked images will be used.</li>
<li>Additional images can be added to a project at any time.</li>
<li>As well as using external apps to import images into Zoetic (as per step 1), images can be imported directly into a project using Zoetic&rsquo;s <em>Add images</em> However, you are likely to find greater flexibility using external apps. It is therefore advisable to share from images apps to Zoetic, rather than Zoetic &ldquo;pulling&rdquo; images from external apps.</li>
<li>Images are sorted, by default, in chronological order from oldest to newest. If an undated image is added to the project it will be added to the start (or end) of the series. The image will then need to be manually moved to its correct location. The series is only automatically sorted once, which is when the images are first added to the project. Any manual re-ordering after that point will be maintained. Alternatively, use the Sort function to add dates to any undated images.</li>
<li>
Ideally, the chosen crop will be completely covered by all the project’s images but where that is not the case, the resulting video will display an exposed ‘background’ that could be distracting.  Beyond just ignoring the issue, various approaches are possible:</li>
<ul>
<li>Redo the crop so that it is completely covered by all the images. This is the best approach but, sometimes, to obtain full coverage the new crop may be deemed to be too small or in the wrong location.</li>
<li>Choose a colour of the background which minimises the distraction e.g. for a project showing a natural landscape, a shade of green may work. (Available in Settings.)</li>
<li>Allow Zoetic to fill in the background using an image from earlier in the sequence. If the scenes are similar, this approach may work quite well, but if they are dissimilar, weird artefacts may appear. (Available in Settings.)</li>
<li>Allow Zoetic to ‘bleed’ the edges of images so that the crop area is fully covered. Provided the exposed area is not too large, this approach usually works quite well. (Available in Settings.)</li>
</ul>
<li>(Pro only) In the Sort function images may be temporarily selected or deselected for processing. Also, the project&rsquo;s target image may be selected.</li>

<p>&nbsp;</p>
<p style="text-align: center; font-size:30px;"><a id="Privacy"></a><strong>Privacy Statement</strong></p>
<p>No personal information is processed or collected. In fact, no information whatsoever leaves your device unless you upload the resulting video and/or images to a third party, such as Google Photos. All processing of the images is undertaken on your device.</p>
<p>If you send logs to Zoetic&rsquo;s author (to help with fault finding) then a small amount of information about your device (model, Android version etc) is included in the logs, in addition to the process flow that Zoetic took up to the point you submit the logs. Zoetic&rsquo;s settings file and current project&rsquo;s settings file are also included in the submission. Paths and project names are likely to be included in the files so you should ensure that when submitting a log you do not use project names or paths that contain personal, or any other form of sensitive, information. Feel free to check what is being submitted by, for example, emailing the logs to yourself before email them to Zoetic's author.</p>
<p>The face/eye detection function uses a capability provided by Google. It runs locally on the device (i.e. images are not uploaded to Google for processing) but if there is still a concern that images might be processed by Google, Zoetic&rsquo;s settings page allows for the function to be hidden and hence unusable.</p>