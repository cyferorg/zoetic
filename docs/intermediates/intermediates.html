<!DOCTYPE html>
<html lang="en">
<meta charset="utf-8" />
<head>
<title>Zoetic Intermediates page</title>
    <meta name="viewport" content="width=device-width,initial-scale=1">
	<link rel="icon" type="image/png" href="../zoeticicon.png"/>
    <!--[if lte IE 8]><link rel="stylesheet" href="../responsive-nav.css"><![endif]-->
    <!--[if gt IE 8]><!--><link rel="stylesheet" href="../styles.css"><!--<![endif]-->
    <script src="../responsive-nav.js"></script>
  </head>

<body>
<script src="../nav.js"></script>

<a id="generatingvideos"></a>
<h2>Generating the videos</h2>

<p>The videos produced by Zoetic are created from a series of images chosen by the user which are used to create a series of intermediate images automatically generated from those user chosen images. The intermediate images are created by combining consecutive pairs of user images so as to produce a smooth (or as specified by the user) transition from one image to the next. The number of intermediates images between consecutive pairs can be specified in three different ways. (The larger the number, the smoother and/or slower the transitions.)</p>
<ol class="inline">
<li>A constant number. This will produce a video which transitions between user images at a constant rate. The user specifies this constant.</li>
<li>A number that is relative to the user image dates. This will produce a video which transitions between consecutive pairs at a speed relative to the period between the image dates. The longer the period, the longer the transition.  A pair of images with dates one day apart will transition seven times faster than a pair of images with dates one week apart. The resulting video will give an impression of how the user images fit within the passage of time. The user specifies a number for the intermediates, as for the previous option, but this number will be used as the average number of intermediates between consecutive images.</li>
<li>A number that is calculated so that the transitions are synchronised with an audio (music) track. The user does not specify a number but instead specifies the music track and various parameters to identify the synchronising musical beats.</li>
</ul>
<p>As well as the above intermediate setting, the user specifies a value for the video's playback speed in frames per second (FPS). For the first two intermediate approaches, the FPS will change the speed of the video. For example, a pair of images with 30 intermediate images between them will take 3 seconds to transition if the FPS is set at 10, whereas it will take just 1 second if the FPS is set at 30. With the music synchronising approach, the FPS will not change the speed of the video (since it obviously has to stay synchronised with the audio track) but rather will alter the smoothness of the playback.</p>
<a id="filters"></a>
<h3>Filters</h3>
<p>Intermediate images are created by combining a weighted first image with a weighted second image. (The sum of the 2 weights sum to 1.) If the weighting for the first image has a value of 0.3, and the weighting for the second a value of 0.7, the transitioned image would be created from combining 30% of the first image and 70% of the second. At the start of the transition, the first image has a weight of 1 and the second image a weight of 0. At the end of the transition the first image has a weight of 0 and the second image a weight of. The weights are calculated using a filter which can be one of the following:</p>
<ol class="inline">
<li>Equal - the transition between consecutive images takes place at a constant rate.</li>
<li>Original - the transition slowly moves away from the first image, increasing speed until it is half way between the images and then slows down as it approaches the second image. This produces intermediate images consisting of images that are closer to the original images.</li>
<li>Original skew - the transition quickly moves from the first image towards the second image, and then slows down as it approaches the second image. This produces a more abrupt transition compared to the above two filters but is useful for videos that need to emphasise the start of the transition, specifically, when synchronising with music.</li>
<li>Immediate - the transition immediately changes from the first image to the second image. This produces an even more abrupt transition than the above filter and, like that filter, is useful for videos that need to emphasise the start of the transition.</li>
</ol>
<img style="margin:20px 20px;border:2px solid black;width:80%" src="../imgs/filters.jpg" alt="Filters" >
<p>A video comparing these four filters can be seen <a href="https://www.youtube.com/watch?v=qrv1-Zpzn4w" style="color: rgb(0,0,255)">here (Google)</a>.</p>
<a id="musicsync"></a>
<h3>Music synchronisation</h3>
<p>From Zoetic's main menu choose <em>Music sync</em>. Tap the music icon at the bottom right of the screen and choose the required audio file. Tap the play button and then adjust the four sliders as described below. The beats are detected by detecting local amplitude peaks (maxima). You are aiming for only the desired beats being detected. If your device struggles with updating the graph and/or the images, one or both of those visualisations can be turned-off by tapping the corresponding 'power' button.</p>
<ul class="inline">
<li>Peak - A beat is detected if the current maximum amplitude is greater than the previous maximum by the specified percentage.</li>
<li>Noise - Any signal below this value is ignored. The noise level is shown on the graph by two horizontal grey lines.</li>
<li>Frequency - The maximum number of beats that are allowed per second.</li>
<li>Max fall - The previous maximum value is decreased by a factor based on this value. (The lower the value, the faster the fall.) A value of 100 results in the previous maximum not being decreased which means for a new beat to be detected there must be an amplitude greater than the previous beat by the <em>Peak</em> percentage. The current maximum is shown on the graph by two red horizontal lines. Note that for higher values of <em>Max fall</em> the red lines can be seen to move slowly inwards. For lower values, the red lines follows the amplitude signals very closely.</li>
</ul>
<pre>
</pre>
<p>The up and down buttons to the right of the graph just scale the graph for visual inspection. They do not change the beats that are detected.</p>
<img style="margin:20px 20px;border:2px solid black;width:40%" src="../imgs/musicsync.jpg" alt="Filters" >
<p>Once the beats are being detected as required, stop the play back and then press play again and this time play through the entire audio track. This will record the beats that will be used by Zoetic to generate the video. Return to the main menu and tap <em>Make video</em>. A video showing these steps can be seen <a href="https://www.youtube.com/watch?v=qk7T0Q4M0n8" style="color: rgb(0,0,255)">here</a>.</p>
<p>Note that during playback, your device's microphone is active (that's how Zoetic listens to the audio track). This means that during playback, you should be sufficiently quiet so the microphone does not pick up any unwanted noise. Alternatively, if you are finding it difficult to set the controls to detect the correct beats, you could increase the noise setting so that Zoetic doesn't detect any beats and then you tap the microphone at the desired beat points.</p>

<pre>


</pre>
<table style="width:100%;background-color: lightgrey;  background-position: center; table-layout: fixed;">
<tr>
<th><A href="javascript:window.history.back();" style=" color: blue">Back</a></th>
<th><a href="../subprojects/subprojects.html" style=" color: blue">Sub-projects</a></th>
</tr>
</table>
</div>
</div>
    <script>
      var navigation = responsiveNav("#nav", {customToggle: ".nav-toggle"});
    </script>
</body>
</html>